{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rldLVW7G0Z3O",
        "outputId": "8dcc2dc5-5250-4c10-e5e9-7f4c37e3299e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\mogam\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\mogam\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mogam\\Desktop\\Work\\Mental Health Chatbot\\mental-health-chatbot-app\\.venv\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "# nltk.download('punkt') # if in case tokenize sentences in words\n",
        "from nltk.stem.lancaster import  LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "# nltk.download('wordnet') \n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64qG54Kb1BWX"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "naqplo1X0Z-l",
        "outputId": "0d471a3b-b809-4829-944e-1a883e9eb7c4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>{'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{'tag': 'morning', 'patterns': ['Good morning'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>{'tag': 'afternoon', 'patterns': ['Good aftern...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>{'tag': 'evening', 'patterns': ['Good evening'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>{'tag': 'night', 'patterns': ['Good night'], '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             intents\n",
              "0  {'tag': 'greeting', 'patterns': ['Hi', 'Hey', ...\n",
              "1  {'tag': 'morning', 'patterns': ['Good morning'...\n",
              "2  {'tag': 'afternoon', 'patterns': ['Good aftern...\n",
              "3  {'tag': 'evening', 'patterns': ['Good evening'...\n",
              "4  {'tag': 'night', 'patterns': ['Good night'], '..."
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_dir = 'data/intents.json'\n",
        "intents = pd.read_json(data_dir)\n",
        "intents.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25odOJXY1JCE"
      },
      "source": [
        "## Tokenizing Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KAOQlsGV1FBw"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?']\n",
        "#loop through each sentence in the intent's patterns\n",
        "for intent in intents['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    w = nltk.word_tokenize(pattern)\n",
        "    words.extend(w)\n",
        "    documents.append((w, intent['tag']))\n",
        "    if intent['tag'] not in classes:\n",
        "      classes.append(intent['tag'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ692UYt1VYf"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "506 documents\n",
            "243 classes ['', ' know  social anxiety? ', ' many issues', ' think about death all the time', 'Addiction,Substance Abuse,Anxiety', 'All I can do is cry and hate myself', 'Am I being picky when it comes to my boyfriend? ', 'Am I going to be alone forever? ', 'Am I somehow stressing myself out? ', 'Am I unworthy of being in a meaningful relationship? ', 'Anger Management', 'Anger Management,Depression,Relationships', 'Anger Management,Domestic Violence', 'Anger Management,Family Conflict', 'Anger Management,Relationships', 'Anger Management,Relationships,Social Relationships', 'Anger Management,Sleep Improvement', 'Anger Management,Social Relationships,Relationships', 'Anger Management,behavioural Change', 'Anxiety, hearing', 'Anxiety,Career counselling', 'Anxiety,behavioural Change', 'Bipolar', 'Can I change my feeling of being worthless to everyone? ', 'Can i learn to be happy alone? ', 'Career counselling,Professional Ethics', 'Crave depression', 'Deal with OCD', 'Depression,Anxiety', 'Depression,Anxiety,Relationships', 'Depression,Anxiety,behavioural Change', 'Depression,Family Conflict', 'Depression,Marriage', 'Depression,Relationships', 'Depression,Self-esteem', 'Depression,Sleep Improvement', 'Depression,Social Relationships', 'Diagnosis,Counselling Fundamentals', 'Difficult communication', 'Dissorder', 'Domestic Violence,Relationships', 'Eating Disorders', 'Eating Disorders,Addiction', 'Eating Disorders,Legal & Regulatory', 'Ex has moved on', 'Family Conflict', 'Family Conflict,Depression', 'Family Conflict,Legal & Regulatory', 'Family Conflict,Relationships,Intimacy', 'Family Conflict,Self-esteem,Parenting,Anxiety', 'Family Conflict,Social Relationships', 'Family Conflict,Stress,Sleep Improvement', 'Family Conflict,Trauma', 'Gift Therapist', 'Grief and Loss', 'Grief and Loss,Depression', 'Grief and Loss,Family Conflict', 'How do I get rid of depression? ', 'How do I know if I have depression?  ', 'Human Sexuality', \"I'm overwhelmed and depressed\", 'Ignoring calls', 'Is this depression? ', 'Lazy', 'Learn emotions', 'Legal & Regulatory,Professional Ethics', 'New therapist', 'Overcome fear', 'Overweight', 'PTSD', 'Paranoia', 'Personality Dissorder', 'Professional Ethics', 'Relationship Anxiety  ', 'Self awareness', 'Should I go back on my medicine? ', 'Sleeping, Anger and Anxiety', 'Social Relationships,Substance Abuse', \"Stop grieving my mother's death\", 'Stressed lately', 'Substance Abuse,Addiction', 'Trust Betrayal', 'Want to be a better human', 'Weed', 'Why I am feeling lonely', 'about', 'affects_whom', 'afford', 'afternoon', 'age group ', 'alcohol', 'always emotional', 'anger help', 'anxiety', 'anxiety  medication? ', 'anxiety attacks', 'anxious', 'ask', 'avoid people', 'behavioural Change', 'behavioural Change,Anxiety', 'behavioural Change,Depression', 'behavioural Change,Social Relationships', 'being called names', 'better', 'biology and depression', 'break', 'breakdows', 'broke but need help', 'casual', 'cause of depression', 'control my temper? ', 'creation', 'cure', 'deal depression', 'deal with a break up', 'deal with someone telling ', 'death', 'death thoughts', 'default', 'definition', 'dep', 'depressed', 'diagnosed with depression', 'done', 'drinking', 'emotionally abused', 'evening', 'expectations', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'failure', 'feeling empty while young', 'find_help', 'friends', 'get over social anxiety', 'goodbye', 'greeting', 'happy', 'hate losing. ', 'hate-me', 'hate-you', 'help', 'highest rate', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'love myself', 'lowest rate', 'lying to parent', 'mad', 'meditation', 'mental-health-fact', 'mom get mad easily', 'morning', 'name', 'need talk to someone', 'neutral-response', 'night', 'no-approach', 'no-response', 'not good enough', 'not love my sister', 'not-talking', 'nothing', 'pandora-useful', 'parents', 'pathological liar', 'physical health? ', 'positive and negative symptoms', 'problem', 'professional_types', 'quit', 'recover', 'repeat', 'sad', 'scared', 'scared of doctor', 'schizophrenia', 'school and depression', 'self-help materials', 'sexual tension', 'signs of psychosis', 'skill', 'sleep', 'sleep and sad', 'smoking', 'social anxiety', 'social situations anxiety', 'something-else', 'steps', 'stressed', 'stressing myself out? ', 'studying abroad', 'stupid', 'suicide', 'thanks', 'therapy', 'throw stuff', 'too fast', 'top cause', 'treatement_options', 'treatment', 'treatment_tips', 'types of depression', 'ugly', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'what_causes', 'worthless', 'wrong']\n",
            "963 unique stemmed words ['!', '$', '%', \"'\", \"'dislocated\", \"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", '(', ')', ',', '.', '10-15', '100', '19', '3', '5,000', '50,000', ':', ';', '``', 'a', 'ability', 'able', 'about', 'abroad', 'absolutely', 'abuse', 'abused', 'abusing', 'abusive', 'academic', 'acknowledge', 'action', 'actually', 'addicted', 'addiction', 'address', 'admitted', 'advice', 'advised', 'affect', 'affected', 'afford', 'afraid', 'after', 'afternoon', 'again', 'age', 'ago', 'agonizing', 'alcohol', 'alive', 'all', 'all-time', 'almost', 'alone', 'along', 'already', 'also', 'always', 'am', 'amount', 'an', 'and', 'anger', 'angry', 'animal', 'annoying', 'another', 'answer', 'anti-depressants', 'antisocial', 'anxiety', 'anxious', 'any', 'anymore', 'anyone', 'anything', 'anywhere', 'apathetic', 'appears', 'approaching', 'appropriate', 'approved', 'are', 'around', 'ask', 'asked', 'aspect', 'at', 'attack', 'au', 'available', 'avoiding', 'awake', 'aware', 'away', 'awful', 'back', 'bad', 'badly', 'barely', 'basis', 'be', 'became', 'because', 'become', 'been', 'before', 'beg', 'begin', 'behaviour', 'behind', 'being', 'belief', 'belittled', 'belong', 'besides', 'betrayed', 'better', 'between', 'big', 'bill', 'binging', 'biological', 'bipolar', 'birth', 'blame', 'blocking', 'blow', 'borrow', 'borrowing', 'bothersome', 'boyfriend', 'break', 'breakdown', 'breathing', 'bring', 'broke', 'broken', 'brother', 'build', 'burned', 'but', 'by', 'bye', 'c', 'ca', 'caged', 'call', 'calling', 'calm', 'came', 'can', 'care', 'case', 'cause', 'caused', 'causing', 'center', 'change', 'changed', 'changing', 'chaos', 'check', 'cheerful', 'child', 'client', 'clingy', 'college', 'come', 'comfortably', 'comment', 'commit', 'communicate', 'communication', 'complacent', 'completely', 'compulsion', 'concentrate', 'confident', 'confronting', 'confused', 'connection', 'consequence', 'constantly', 'contemplated', 'continue', 'control', 'controlling', 'convince', 'cope', 'could', 'counsellor', 'country', 'course', 'cousin', 'crave', 'crazy', 'created', 'creating', 'cried', 'crowd', 'cry', 'culture', 'cure', 'cured', 'current', 'currently', 'cursing', 'cycle', 'dad', 'daily', 'dance', 'daughter', 'day', 'day-to-day', 'deal', 'death', 'debilitating', 'debt', 'decided', 'deep', 'define', 'definitely', 'deny', 'depressed', 'depression', 'depressive', 'describe', 'deserve', 'despair', 'dessert', 'diagnose', 'diagnosed', 'did', 'die', 'died', 'difference', 'different', 'difficult', 'difficulty', 'disagrees', 'disappear', 'disclose', 'disgusting', 'disorder', 'distant', 'distrust', 'do', 'doctor', 'doe', 'doing', 'done', 'down', 'drama', 'dream', 'drink', 'drinking', 'driving', 'drug', 'due', 'dumb', 'ear', 'early', 'easier', 'easily', 'easy', 'eat', 'eating', 'edge', 'effect', 'either', 'electroshock', 'elementary', 'else', 'emotion', 'emotional', 'emotionally', 'empty', 'end', 'enjoy', 'enough', 'entirely', 'especially', 'ethical', 'even', 'evening', 'event', 'ever', 'every', 'everyone', 'everything', 'ex', 'ex-boyfriend', 'ex-friends', 'exam', 'excuse', 'experience', 'experienced', 'experiencing', 'explosive', 'express', 'externally', 'extreme', 'extremely', 'f', 'face', 'fact', 'fail', 'family', 'fare', 'fast', 'father', 'fear', 'fearful', 'feedback', 'feel', 'feeling', 'fell', 'felt', 'few', 'fiance', 'fighting', 'figure', 'fill', 'financial', 'find', 'fine', 'first', 'five', 'fix', 'focus', 'focusing', 'follow', 'followed', 'food', 'for', 'forgetting', 'forward', 'fought', 'four', 'freak', 'friend', 'friendship', 'from', 'frustrated', 'fulfillment', 'full', 'fully', 'functioning', 'future', 'gain', 'gained', 'gaining', 'gamble', 'game', 'gastric', 'gave', 'get', 'getting', 'gift', 'girl-friend', 'girlfriend', 'give', 'go', 'going', 'gone', 'good', 'goodbye', 'got', 'graceful', 'grade', 'graduate', 'graduated', 'great', 'grew', 'grief', 'grieving', 'group', 'growing', 'guess', 'ha', 'habari', 'habit', 'had', 'hair', 'half', 'hand', 'happen', 'happened', 'happening', 'happy', 'hard', 'harder', 'hardly', 'harm', 'harming', 'hate', 'hated', 'have', 'having', 'haze', 'he', 'head', 'health', 'hear', 'heard', 'hearing', 'heart', 'hello', 'help', 'helpful', 'her', 'here', 'hey', 'hi', 'high', 'highest', 'him', 'hip', 'his', 'hit', 'hmmm', 'hold', 'hole', 'home', 'hopeless', 'horrible', 'hour', 'how', 'however', 'human', 'hurt', 'hurting', 'husband', 'i', 'idea', 'if', 'ignore', 'ill', 'illness', 'imagine', 'importance', 'important', 'in', 'increased', 'infested', 'information', 'ink', 'insecure', 'inside', 'insomnia', 'instead', 'intense', 'interest', 'interested', 'internal', 'internally', 'into', 'involved', 'irritability', 'is', 'issue', 'it', 'job', 'joke', 'judging', 'just', 'k', 'keen', 'keep', 'keeping', 'kept', 'kick', 'kill', 'killing', 'kind', 'know', 'lack', 'large', 'lash', 'last', 'lately', 'later', 'laziness', 'lazy', 'le', 'lead', 'learn', 'learning', 'leave', 'leaving', 'left', 'legitimate', 'let', 'letting', 'liar', 'lie', 'lied', 'life', 'light', 'light-headed', 'like', 'liked', 'lingering', 'list', 'listen', 'literally', 'live', 'living', 'location', 'lonely', 'long', 'loosing', 'lose', 'losing', 'lost', 'lot', 'loud', 'love', 'loved', 'low', 'lowest', 'lying', 'mad', 'made', 'maintain', 'major', 'make', 'making', 'manage', 'manifested', 'many', 'marijuana', 'material', 'matter', 'may', 'me', 'mean', 'medication', 'medicine', 'meditation', 'men', 'mental', 'mentaly', 'mentioned', 'mess', 'might', 'mind', 'mine', 'minor', 'minute', 'miserable', 'missed', 'mistake', 'mom', 'moment', 'money', 'monster', 'month', 'moody', 'more', 'morning', 'most', 'mother', 'move', 'much', 'mum', 'music', 'my', 'myself', \"n't\", 'name', 'nausea', 'need', 'needed', 'negative', 'nervous', 'never', 'new', 'nice', 'night', 'nightmare', 'no', 'nobody', 'normal', 'normally', 'not', 'nothing', 'notice', 'noticed', 'noticing', 'now', 'obsessive-compulsive', 'ocd', 'of', 'off', 'offending', 'oh', 'ok', 'okay', 'old', 'on', 'one', 'only', 'open', 'option', 'or', 'other', 'others', 'otherwise', 'our', 'out', 'outgoing', 'over', 'overcoe', 'overcome', 'overweight', 'overwhelmed', 'own', 'pain', 'pained-filled', 'paired', 'panic', 'paranoia', 'parent', 'parental', 'partner', 'passed', 'past', 'pathological', 'pattern', 'people', 'person', 'personality', 'petty', 'phone', 'physical', 'physically', 'picky', 'pill', 'place', 'playing', 'please', 'pleasure', 'plug', 'point', 'poorly', 'positive', 'possessive', 'possessiveness', 'possible', 'possibly', 'practicing', 'prepared', 'prescription', 'present', 'presentation', 'prevent', 'probably', 'problem', 'procrastination', 'professional', 'program', 'prohibited', 'prohibiting', 'proper', 'psychologist', 'psychology', 'psychosis', 'ptsd', 'public', 'pull', 'push', 'put', 'putting', 'quit', 'quite', 'random', 'randomly', 'rate', 'rather', 'reaction', 'read', 'really', 'reason', 'recently', 'reciprocated', 'record', 'recover', 'refuse', 'regained', 'regret', 'relationship', 'relieve', 'religious', 'relocated', 'remaining', 'remember', 'repeating', 'repressed', 'reproduce', 'requires', 'response', 'rest', 'revoir', 'rid', 'right', 'robot', 'room', 'ruining', 'rumour', 'run', 'sad', 'sadness', 'said', 'sarcastic', 'sasa', 'say', 'saying', 'sayonara', 'scared', 'schizophrenia', 'school', 'scream', 'screaming', 'second', 'see', 'seeing', 'seem', 'self', 'self-confidence', 'self-help', 'sense', 'several', 'severe', 'sexual', 'shake', 'she', 'shock', 'should', 'show', 'shut', 'shy', 'sibling', 'sick', 'sign', 'simplest', 'since', 'sister', 'sits', 'situation', 'skin', 'sleep', 'sleeping', 'sleeve', 'slept', 'slow', 'smoking', 'so', 'sob', 'social', 'some', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'soon-to-be', 'sooner', 'sound', 'speak', 'spends', 'spiral', 'spurt', 'stabbed', 'stand', 'start', 'started', 'starting', 'state', 'status', 'stay', 'step', 'stick', 'still', 'stomach', 'stop', 'stopped', 'story', 'straight', 'straight-a', 'stress', 'stressed', 'stressing', 'struggling', 'stuck', 'student', 'studying', 'stuff', 'stupid', 'stuttering', 'such', 'suffering', 'suggested', 'suggestion', 'suicidal', 'suicide', 'super', 'support', 'supposed', 'sure', 'surgery', 'sweaty', 'sweet', 'symptom', 'take', 'taken', 'taking', 'talk', 'talking', 'teen', 'tell', 'telling', 'temper', 'tend', 'tension', 'terrible', 'than', 'thank', 'thanks', 'that', 'the', 'thee', 'their', 'them', 'then', 'therapist', 'therapy', 'there', 'these', 'they', 'thing', 'think', 'thinking', 'this', 'those', 'though', 'thought', 'through', 'throw', 'time', 'tired', 'to', 'today', 'together', 'told', 'too', 'took', 'top', 'tough', 'towards', 'tragic', 'trail', 'train', 'treated', 'treatment', 'tried', 'trouble', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'tunnel', 'turn', 'turned', 'twin', 'twisted', 'type', 'ugly', 'unaccomplished', 'underlying', 'understand', 'understands', 'undiagnosed', 'unemployed', 'unidentifiable', 'unsure', 'unwell', 'unwillingness', 'up', 'upset', 'urge', 'use', 'used', 'useful', 'useless', 'usually', 'verge', 'very', 'violent', 'voice', 'wa', 'want', 'wanted', 'warning', 'watching', 'way', 'we', 'weed', 'week', 'weight', 'weird', 'well', 'wellbutrin', 'went', 'were', 'what', 'whatever', 'wheel', 'when', 'whenever', 'where', 'which', 'while', 'who', 'why', 'wife', 'will', 'window', 'wish', 'with', 'without', 'wo', 'wondering', 'word', 'work', 'worked', 'worker', 'working', 'worn', 'worried', 'worth', 'worthless', 'would', 'writing', 'wrong', 'yako', 'yeah', 'year', 'yes', 'yet', 'yo', 'you', 'your', 'yourself', 'zombie-like']\n"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore]\n",
        "words = sorted(list(set(words)))\n",
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print(len(documents),'documents')\n",
        "print(len(classes), 'classes', classes)\n",
        "print(len(words), 'unique stemmed words', words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiXB_1e51miK"
      },
      "source": [
        "## Creating Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCT1awWe1FGr",
        "outputId": "a47c1558-eca8-4bba-dbf5-c182b2797232"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "output = []\n",
        "output_empty = [0] * len(classes)\n",
        "\n",
        "for doc in documents: \n",
        "  bag = []\n",
        "  pattern_words = doc[0]\n",
        "  pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "  for w in words:\n",
        "    bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "  output_row = list(output_empty)\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  training.append([bag,output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16rKH7Uc19WL"
      },
      "source": [
        "## Creating Model & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "je1FK3QR2FhK"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzBoqvol19wa",
        "outputId": "51e46ff9-a537-4fe5-c42d-85067aae000a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\mogam\\Desktop\\Work\\Mental Health Chatbot\\mental-health-chatbot-app\\.venv\\lib\\site-packages\\tflearn\\initializations.py:164: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        }
      ],
      "source": [
        "# DNN\n",
        "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
        "net = tflearn.fully_connected(net, 10)\n",
        "net = tflearn.fully_connected(net, 10)\n",
        "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
        "net = tflearn.regression(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dKzIKK9f7sGx"
      },
      "outputs": [],
      "source": [
        "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSshjlvm191b",
        "outputId": "861d489c-5c51-41c9-e776-a5c72d6da7d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Step: 63999  | total loss: \u001b[1m\u001b[32m0.04101\u001b[0m\u001b[0m | time: 0.455s\n",
            "| Adam | epoch: 1000 | loss: 0.04101 - acc: 0.9617 -- iter: 504/506\n",
            "Training Step: 64000  | total loss: \u001b[1m\u001b[32m0.05863\u001b[0m\u001b[0m | time: 0.461s\n",
            "| Adam | epoch: 1000 | loss: 0.05863 - acc: 0.9655 -- iter: 506/506\n",
            "--\n"
          ]
        }
      ],
      "source": [
        "model.fit(train_x, train_y, n_epoch = 1000, batch_size=8, show_metric=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ghxIVlV2194-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:c:\\Users\\mogam\\Desktop\\Work\\Mental Health Chatbot\\mental-health-chatbot-app\\py_model\\tlmodel\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ]
        }
      ],
      "source": [
        "model.save('tlmodel/model.tflearn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "d3E3ocWt2aVR"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "pickle.dump({'words' : words, 'classes':classes, 'train_x': train_x, 'train_y' : train_y}, open('data/training_data', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82d_SWVz2bkq"
      },
      "source": [
        "## Chatbot Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S683GYAd2aXt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from c:\\Users\\mogam\\Desktop\\Work\\Mental Health Chatbot\\mental-health-chatbot-app\\py_model\\tlmodel\\model.tflearn\n"
          ]
        }
      ],
      "source": [
        "data = pickle.load(open('data/training_data','rb'))\n",
        "words = data['words']\n",
        "classes = data['classes']\n",
        "train_x = data['train_x']\n",
        "train_y = data['train_y']\n",
        "\n",
        "model.load('tlmodel/model.tflearn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxfhT1J_2sZf"
      },
      "source": [
        "## Creating methods for calling chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lH6nnZNY2aak"
      },
      "outputs": [],
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "  return sentence_words\n",
        "\n",
        "def bow(sentence, words, show_details = False):\n",
        "  sentence_words = clean_up_sentence(sentence)\n",
        "  bag = [0]*len(words)\n",
        "  for s in sentence_words:\n",
        "    for i,w in enumerate(words):\n",
        "      if w==s:\n",
        "        bag[i] = 1\n",
        "        if show_details:\n",
        "          print('found in bag: %s' % w)\n",
        "  return (np.array(bag))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jktu3G872ac7"
      },
      "outputs": [],
      "source": [
        "context = {}\n",
        "\n",
        "ERROR_THRESHOLD = 0.25\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    # filter out predictions below a threshold\n",
        "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
        "    # sort by strength of probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append((classes[r[0]], r[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return return_list\n",
        "\n",
        "def response(sentence, userID='123', show_details=False):\n",
        "    results = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "    if results:\n",
        "        # loop as long as there are matches to process\n",
        "        while results:\n",
        "            for i in intents['intents']:\n",
        "                # find a tag matching the first result\n",
        "                if i['tag'] == results[0][0]:\n",
        "                    # set context for this intent if necessary\n",
        "                    if 'context_set' in i:\n",
        "                        if show_details: print ('context:', i['context_set'])\n",
        "                        context[userID] = i['context_set']\n",
        "\n",
        "                    # check if this intent is contextual and applies to this user's conversation\n",
        "                    if not 'context_filter' in i or \\\n",
        "                        (userID in context and 'context_filter' in i and i['context_filter'] == context[userID]):\n",
        "                        if show_details: print ('tag:', i['tag'])\n",
        "                        # a random response from the intent\n",
        "                        return random.choice(i['responses'])\n",
        "\n",
        "            results.pop(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nZOEw9w2_Xq"
      },
      "source": [
        "Testing Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkcCMcO82agp",
        "outputId": "e2edcf71-369f-4f07-cca7-6f865ec6a6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You can call me Well-being Buddy. \n"
          ]
        }
      ],
      "source": [
        "print(response('What is your name?'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLJT44M90aBK",
        "outputId": "a3bea525-55da-4b54-df99-37ba181a882b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start talking with the chatbot (type quit to stop)!\n",
            "Bot: Sorry, I didn't understand you. \n",
            "Bot: Sorry, I didn't understand you. \n"
          ]
        }
      ],
      "source": [
        "# define a function to start the chatbot\n",
        "def chatbot():\n",
        "    print('Start talking with the chatbot (type quit to stop)!')\n",
        "    while True:\n",
        "        inp = input('You: ')\n",
        "        if inp.lower() == 'quit':\n",
        "            break\n",
        "        response_output = response(inp)\n",
        "        print('Bot:', response_output)\n",
        "\n",
        "# start the chatbot\n",
        "chatbot()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
